{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitricardovirtualenv4a6c0f1ff0b9416598a65697d26887ab",
   "display_name": "Python 3.7.4 64-bit ('Ricardo': virtualenv)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP - Computação Natural\n",
    "#### \"Predict whether a mammogram mass is benign or malignant\"\n",
    "\n",
    "1. BI-RADS assessment: 1 to 5 (ordinal)  \n",
    "2. Age: patient's age in years (integer)\n",
    "3. Shape: mass shape: round=1 oval=2 lobular=3 irregular=4 (nominal)\n",
    "4. Margin: mass margin: circumscribed=1 microlobulated=2 obscured=3 ill-defined=4 spiculated=5 (nominal)\n",
    "5. Density: mass density high=1 iso=2 low=3 fat-containing=4 (ordinal)\n",
    "6. Severity: benign=0 or malignant=1 (binominal)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('mammographic_masses.data.txt')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Convert missing data (indicated by a ?) into NaN and add the appropriate column names (BI_RADS, age, shape, margin, density, and severity) **"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace('?',np.nan)\n",
    "data.columns = ['BI_RADS','Age','Shape','Margin','Density','Severity']\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Drop BI_RADS column because it has no influence on the severity forecast **"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['BI_RADS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Convert datatype 'object' to 'float64' **  "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.astype(float)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing missing values\n",
    "**First we get the missing values per feature.**\n",
    "\n",
    "*Lets check them out as well*"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_feature = data.isnull().sum(axis=0)\n",
    "graph = missing_values_feature.drop(labels='Severity')\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(131)\n",
    "plt.bar(graph.axes[0].to_list(), graph.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We then develop a heatmap to give us some more information*"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data.isnull(),yticklabels=False,cbar=False,cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Finally we can check the percentage of missing values per feature*"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_missing = data.isnull().sum() * 100 / len(data)\n",
    "missing_value_df = pd.DataFrame({'percent_missing': percent_missing})\n",
    "print(missing_value_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After analysing the columns, we should have a look at the rows**"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_missing = len(data.columns) - (data.apply(lambda x: x.count(), axis=1))\n",
    "missing_values_data_rows = pd.DataFrame({'data_missing':data_missing})\n",
    "missing_values_data_rows.sort_values('data_missing',inplace=True,ascending=False)\n",
    "missing_values_data_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now lets analyse the missing data per class (Severity = 0 or Severity = 1).**\n",
    "\n",
    "*First we group the missing values per class*"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = data.groupby('Severity')\n",
    "missing_values_class = grouped_data.count().rsub(grouped_data.size(), axis=0)\n",
    "missing_values_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Now we split the dataframe per class so we can draw our plot*"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_new_1, m_new_2 = missing_values_class.head(1), missing_values_class.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(m_new_1.axes[1].to_list()))\n",
    "width = 0.4\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, m_new_1.values[0], width=width, label = \"Severity 0\")\n",
    "rects2 = ax.bar(x + width/2, m_new_2.values[0], width=width, label = \"Severity 1\")\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(m_new_1.axes[1].to_list())\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally, for each class we're going to calculate the number of rows that have 1 and 2 NaN values**"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_mv1_sv0 = 0\n",
    "rows_mv2_sv0 = 0\n",
    "rows_mv1_sv1 = 0\n",
    "rows_mv2_sv1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in data.iterrows():\n",
    "    if(row['Severity'] == 0):\n",
    "        if(row.isnull().sum() == 1):\n",
    "            rows_mv1_sv0 += 1\n",
    "        elif(row.isnull().sum() == 2):\n",
    "            rows_mv2_sv0 += 1\n",
    "    else:\n",
    "        if(row.isnull().sum() == 1):\n",
    "            rows_mv1_sv1 += 1\n",
    "        elif(row.isnull().sum() == 2):\n",
    "            rows_mv2_sv1 += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We create a dataframe only for visualization purpose*"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberofnan_class = pd.DataFrame(np.array([[rows_mv1_sv0,rows_mv2_sv0], [rows_mv1_sv1,rows_mv2_sv1]]), \n",
    "                                    index=['Severity 0','Severity 1'], columns=['1 NaN', '2 NaN'])\n",
    "numberofnan_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['1 NaN', '2 NaN']\n",
    "x = np.arange(len(labels))\n",
    "width = 0.4\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width/2, [rows_mv1_sv0,rows_mv2_sv0], width=width, label = \"Severity 0\")\n",
    "rects2 = ax.bar(x + width/2, [rows_mv1_sv1,rows_mv2_sv1], width=width, label = \"Severity 1\")\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*With this information we can also see the number of rows with 1 or 2 missing values per class*"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_class = pd.DataFrame(np.array([[rows_mv1_sv0+rows_mv2_sv0], [rows_mv1_sv1+rows_mv2_sv1]]), \n",
    "                                    index=['Severity 0','Severity 1'], columns=['Sum'])\n",
    "nan_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 5))\n",
    "plt.bar(['Severity 0','Severity 1'],[rows_mv1_sv0+rows_mv2_sv0,rows_mv1_sv1+rows_mv2_sv1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** The missing data seems randomly distributed, so we decided to go with the following strategy: **\n",
    "\n",
    "* Drop rows with 2 NaN values\n",
    "\n",
    "* Replace the NaN values from rows with 1 missing value\n",
    "\n",
    "*First we get the mode of every feature for each class*"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_sv0 = data[data['Severity'] == 0].mode()\n",
    "mode_sv1 = data[data['Severity'] == 1].mode()\n",
    "mode_sv0 = mode_sv0.drop([1])\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(mode_sv0)\n",
    "    print(mode_sv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*After we create conditions to replace the NaN values on rows with 1 missing value.*\n",
    "\n",
    "*For that we need the index of the rows which have 1 missing value.*"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_1nan = missing_values_data_rows.index[missing_values_data_rows['data_missing'] == 1].tolist()\n",
    "mask_sv0 = (data['Severity'] == 0) & (data.index.isin(rows_1nan))\n",
    "mask_sv1 = (data['Severity'] == 1) & (data.index.isin(rows_1nan))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We can now proceed and replace the missing values for their class mode* "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[mask_sv0, 'Shape'] = data.loc[mask_sv0, 'Shape'].fillna(mode_sv0.loc[0,'Shape'])\n",
    "data.loc[mask_sv0, 'Margin'] = data.loc[mask_sv0, 'Margin'].fillna(mode_sv0.loc[0,'Margin'])\n",
    "data.loc[mask_sv0, 'Density'] = data.loc[mask_sv0, 'Density'].fillna(mode_sv0.loc[0,'Density'])\n",
    "data.loc[mask_sv1, 'Age'] = data.loc[mask_sv1, 'Age'].fillna(mode_sv1.loc[0,'Age'])\n",
    "data.loc[mask_sv1, 'Shape'] = data.loc[mask_sv1, 'Shape'].fillna(mode_sv1.loc[0,'Shape'])\n",
    "data.loc[mask_sv1, 'Margin'] = data.loc[mask_sv1, 'Margin'].fillna(mode_sv1.loc[0,'Margin'])\n",
    "data.loc[mask_sv1, 'Density'] = data.loc[mask_sv1, 'Density'].fillna(mode_sv1.loc[0,'Density'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Finally, we can drop rows with NaN values because the only ones that are left are the ones with 2 NaN*"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()\n",
    "data.index = np.arange(1, len(data) + 1)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** !!! (Ou podemos meter os dados que faltavam, ver isto) !!! **"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Countplot of the Severity (Benign 0 vs Malignant 1) **"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Severity',data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Histogram showing Age based on the Severity column **"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "g = sns.FacetGrid(data,hue=\"Severity\",palette='coolwarm',size=6,aspect=2)\n",
    "g = (g.map(plt.hist,'Age',bins=20,alpha=0.7)).add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Detect outliers: https://towardsdatascience.com/ways-to-detect-and-remove-the-outliers-404d16608dba"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect Outliers using Box plot (Uni-variate outlier)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=data['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=data['Shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=data['Margin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=data['Density'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect Outliers using Scatter plot (Multi-variate outlier)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "ax.scatter(data['Age'], data['Shape'])\n",
    "ax.set_xlabel('Age')\n",
    "ax.set_ylabel('Shape')\n",
    "#ax.set_ylabel('Margin')\n",
    "#ax.set_ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect outliers using mathematical function Z-Score"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.abs(stats.zscore(data))\n",
    "threshold = 3\n",
    "print(np.where(z > threshold))\n",
    "# The first array contains the list of row numbers and second array respective column numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column 3 (density) has all outliers"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect outliers using IQR Score\n",
    "Similar to Z-Score"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = data.quantile(0.25)\n",
    "Q3 = data.quantile(0.75)\n",
    "iqr = Q3 - Q1\n",
    "print(iqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Não curti ...\n",
    "print(data < (Q1 - 1.5 * iqr)) |(data > (Q3 + 1.5 * iqr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Outliers using Z-Score\n",
    "\n",
    "##### + explanations: https://stackoverflow.com/questions/23199796/detect-and-exclude-outliers-in-pandas-data-frame"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Só fazer 1 vez\n",
    "data = data[(np.abs(stats.zscore(data)) < 3).all(axis=1)]\n",
    "data.index = np.arange(1, len(data) + 1)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting pandas dataframes to numpy arrays"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data.drop('Severity',axis=1).to_numpy()\n",
    "y_train = data['Severity'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing the attribute data using StandardScaler"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}